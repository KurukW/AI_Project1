{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "afraid-wright",
   "metadata": {},
   "source": [
    "# Modele de réseau neuronale"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moderate-transfer",
   "metadata": {},
   "source": [
    "19/4/21 11:20\n",
    "Un nouveau modele est pret à être train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "human-distribution",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "urban-apollo",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "#import seaborn as sns #On ne sait jamais que ça serve\n",
    "import pandas as pd \n",
    "from sklearn.preprocessing import MinMaxScaler #Normalisation #Il faut l'installer aussi avec conda install\n",
    "import random\n",
    "from math import ceil\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, Sequential\n",
    "from tensorflow.keras.layers import  Dense, Conv3D, BatchNormalization,MaxPooling3D, Dropout, LSTM, ConvLSTM2D\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "\n",
    "#conda install pydot\n",
    "#conda install pydotplus\n",
    "#conda install graphviz\n",
    "from tensorflow.keras.utils import plot_model\n",
    "#import pydot\n",
    "\n",
    "#Afin que keras ne réinitialise pas les poids quand on enregistre le modèle\n",
    "from tensorflow.keras.backend import manual_variable_initialization \n",
    "manual_variable_initialization(True)\n",
    "\n",
    "import threading\n",
    "from queue import Queue, Empty\n",
    "from time import sleep, time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "owned-chicago",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "indian-knitting",
   "metadata": {},
   "source": [
    "### Paramètres généraux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "solar-freight",
   "metadata": {},
   "outputs": [],
   "source": [
    "fps = 10\n",
    "size = (120,90) #(40,30)\n",
    "nb_classes = 10 #Nombre de classes\n",
    "epochs = 3\n",
    "batch_size = 20\n",
    "pack_size = 40\n",
    "learning_rate = 0.002\n",
    "modele_n = \"12\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outer-galaxy",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verification qu'un modele avec ces paramètres n'existe pas déjà\n",
    "folder = 'Saved_model'\n",
    "modele_type = 'model_convLSTM2D'\n",
    "param = f\"_{modele_n}_{fps}_{size[1]}_{size[0]}_{nb_classes}_{epochs}_{batch_size}_{pack_size}_{int(learning_rate*1000)}mili\"\n",
    "full_name = folder + '\\\\' + modele_type + param\n",
    "print(full_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comparable-crystal",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    model_saved = keras.models.load_model(full_name + \".h5\")\n",
    "    print(\"Pas besoin d'aller plus loin, le modele a déjà été fabriqué\")\n",
    "    model_charge = True\n",
    "except:\n",
    "    print(\"Modele non testé\")\n",
    "    model_charge = False\n",
    "    #Enregistrement sur Tensorboard\n",
    "    #tensorboard = TensorBoard(log_dir='Saved_model\\\\logs\\\\{}'.format(full_name),)\n",
    "    #Il faut ouvrir la commande dans le dossier Saved_model et taper:\n",
    "    #tensorboard --logdir = logs/\n",
    "    #Ensuite un browser s'ouvre, et sinon on a une URL à mettre dessus\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "retained-candy",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "lonely-casino",
   "metadata": {},
   "source": [
    "## Fonctions d'imports et preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wound-vinyl",
   "metadata": {},
   "source": [
    "#### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "humanitarian-celebrity",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mov_imgs_from_path(path,fps = -1,color = 'gray'):\n",
    "    '''\n",
    "    Retourne une liste d'images pour une vidéo. La liste d'image a le nombre de fps voulu\n",
    "    reprend que le mouvement\n",
    "    '''\n",
    "    \n",
    "    cap = cv2.VideoCapture(path)\n",
    "    try:\n",
    "        fps_actu = cap.get(cv2.CAP_PROP_FPS)\n",
    "    #     print(f\"Traitement de la video n° {path}       \",end=\"\\r\")\n",
    "        if fps <= -1: fps = fps_actu #Je peux ne pas donner de fps et ça va prendre le nombre d'fps initial\n",
    "        ecart_voulu = int(1000/fps)\n",
    "        ecart_initial = int(1000/fps_actu)\n",
    "        imgs = []\n",
    "\n",
    "        ret, frame = cap.read()\n",
    "        while(cap.isOpened()):\n",
    "            prev = frame\n",
    "            ret, frame = cap.read()\n",
    "\n",
    "\n",
    "\n",
    "            if ret: #Sinon ça plante quand il n'y a plus d'images\n",
    "                #Récupère seulement certaines images\n",
    "                t_ms = cap.get(cv2.CAP_PROP_POS_MSEC)\n",
    "                modulo = t_ms % ecart_voulu\n",
    "                if modulo < ecart_initial:\n",
    "                    #Isoler les images\n",
    "\n",
    "                    if color == 'gray':\n",
    "                        gray = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "                        prev_gray = cv2.cvtColor(prev,cv2.COLOR_BGR2GRAY)\n",
    "                        diff_gray = cv2.absdiff(gray,prev_gray)\n",
    "\n",
    "                    elif color == 'rgb':\n",
    "                        diff_gray = cv2.absdiff(frame,prev) \n",
    "\n",
    "                    #On va travailler avec des images en nuance de gris, c'est bcp plus simple\n",
    "                    imgs.append(diff_gray)\n",
    "\n",
    "            else: #Va jusqu'au bout de la vidéo\n",
    "                break\n",
    "        else:\n",
    "            print(\"Le fichier n'a pas pu être ouvert\")\n",
    "    except:\n",
    "        print(f\"IL Y A UN PROBLEME AVEC LA VIDEO: {path}\")\n",
    "        return None\n",
    "    cap.release()\n",
    "    \n",
    "    return imgs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "current-saturn",
   "metadata": {},
   "source": [
    "#### Resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "voluntary-importance",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_imgs(imgs,nsize):\n",
    "    '''\n",
    "    Change la taille de l'image.\n",
    "    Le premier élément de nsize est la longueur (width), le deuxième la hauteur (height)\n",
    "    '''\n",
    "    return [cv2.resize(img, dsize=nsize, interpolation=cv2.INTER_LINEAR) for img in imgs]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "experienced-primary",
   "metadata": {},
   "source": [
    "#### Normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "monthly-greeting",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_imgs(imgs):\n",
    "    '''\n",
    "    Normalise une série d'images\n",
    "    On divise par le max de l'image parce que certains bons modèles ont été entrainé comme cela\n",
    "    '''\n",
    "    liste = []\n",
    "    for img in imgs:\n",
    "        max_ = float(img.max())\n",
    "        if max_ != 0:\n",
    "            liste.append(img/max_)\n",
    "        else:\n",
    "            liste.append(img)\n",
    "    return liste"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "russian-degree",
   "metadata": {},
   "source": [
    "## Fonction de générateur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "institutional-biology",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_gen(labels_list, folder_path, pack_size = 10, pointer = 0, fps = 5, size = (160,120)):\n",
    "    '''\n",
    "    à partir de la liste des labels et de la position du foler\n",
    "    Retourne:\n",
    "    -une liste d'images de vidéos de shape (pack_size,n_frames,height,width[,channels])\n",
    "        n_frames = fps*2.4\n",
    "    -Une liste de numérique avec les labels correspondant aux images (de len = batch_size)\n",
    "    -Un pointer qui permet de faire tourner my_gen à nouveau et recevoir les éléments suivants de la liste\n",
    "    \n",
    "    \n",
    "    Normalement on peut envoyer X et y_num dans le modele directement (avec fit ou train_on_batch, les deux devraient fonctionner)\n",
    "    Je vais essayer de travailler avec des thread pour avoir un thread en Train et un trhead en gen\n",
    "    '''\n",
    "    #Affiche combien de paquets il faudra\n",
    "    len_label = len(labels_list)\n",
    "    if pointer == 0:\n",
    "        #Uniquement le premier passage\n",
    "        nb_pack = ceil(len_label/pack_size)\n",
    "        print(f\"Il y aura {nb_pack} packs de {min(pack_size,len_label)} vidéos à importer\")\n",
    "    else:\n",
    "        print(f\"Il reste encore {len_label - pointer} vidéos à importer\")\n",
    "    \n",
    "    y_num = []\n",
    "    X = []\n",
    "    for i in range(pointer, pack_size + pointer):\n",
    "        pointer = i+1\n",
    "        if i >= len_label:\n",
    "            break\n",
    "        label, video_name = labels_list[i]\n",
    "        \n",
    "        #Label en numérique\n",
    "        y_num.append(labels_n[label])\n",
    "        \n",
    "        #Preprocess d'images\n",
    "        file_path = folder_path + \"\\\\\" + video_name\n",
    "        imgs_of_video = get_mov_imgs_from_path(file_path,fps,'gray') #Gray ou rgb\n",
    "        if imgs_of_video == None:\n",
    "            continue\n",
    "        resized_imgs = resize_imgs(imgs_of_video, size)\n",
    "        norm_imgs = normalize_imgs(resized_imgs)\n",
    "        \n",
    "        X.append(norm_imgs)\n",
    "        \n",
    "    print() #Pour ne pas écrire sur la même ligne qu'avant\n",
    "    X = np.array(X)\n",
    "    y = np.array(y_num)\n",
    "    \n",
    "    #Ajouter une dimsension en à la fin est nécessaire pour certains modèle\n",
    "    #Commenter cette ligne si ce n'est pas nécessaire\n",
    "    X = np.expand_dims(X, axis=len(X.shape)) \n",
    "    \n",
    "    # Si le modele est compile avec :loss='sparse_categorical_crossentropy'\n",
    "    # Il faut un y catégorique , faire ça hors de la fonction\n",
    "    #y = to_categorical(y, num_classes = nb_classes)\n",
    "\n",
    "    return (X, y, pointer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "destroyed-sleep",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_thread(labels_list, folder_path, pack_size = 10, fps = 5, size = (160,120)):\n",
    "    '''\n",
    "    S'assure que my_gen tourne toujours en parallèle du fit. Il prépare toujours 2 paquets de vidéo en avance\n",
    "    '''\n",
    "    pointer = 0\n",
    "    while pointer < len(labels_list):\n",
    "        X,y,pointer = my_gen(labels_list, folder_path, pack_size, pointer, fps, size)\n",
    "        q.put((X,y))\n",
    "        print(f\"Pack of {pack_size} videos put in queue\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stainless-alliance",
   "metadata": {},
   "source": [
    "## Fabrication des modeles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "experienced-intersection",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "standard-still",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_simpler_model(n_frames = 24, height = 120, width = 160, channels = 1, nb_classes = 10):\n",
    "    \n",
    "    sample_shape = (n_frames,height,width,channels) #width = 160, height = 120, nframes = 24, 3 channels si on est en RGB (si on est en gris on sait pas)\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv3D(256, strides =(1,1,1), padding='same', kernel_size=(5, 5, 5),\n",
    "                     activation='relu', kernel_initializer='he_uniform',\n",
    "                     input_shape=sample_shape,data_format='channels_last'))    \n",
    "    model.add(Dense(256, activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(MaxPooling3D(pool_size=(3,3, 3),data_format = 'channels_first'))\n",
    "    model.add(BatchNormalization(center=True, scale=True))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Conv3D(64, strides=(1,1,1), padding=\"same\", kernel_size=(3, 3, 3),\n",
    "                     activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(Dense(64, activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(MaxPooling3D(pool_size=(1,2, 2)))\n",
    "    model.add(BatchNormalization(center=True, scale=True))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "\n",
    "\n",
    "    #LSTM\n",
    "    \n",
    "    model.add(ConvLSTM2D(filters = 64,kernel_size = (5,5),activation=\"tanh\",\n",
    "                         recurrent_activation=\"sigmoid\",return_sequences = True))\n",
    "    model.add(ConvLSTM2D(filters = 64,kernel_size = (3,3),activation=\"tanh\",\n",
    "                         recurrent_activation=\"sigmoid\",return_sequences = True))\n",
    "    model.add(layers.Reshape((24,8064)))\n",
    "    model.add(LSTM(units = 64,activation=\"tanh\", recurrent_activation=\"sigmoid\",\n",
    "                   return_sequences = False))\n",
    "    \n",
    "\n",
    "    #softmax\n",
    "    model.add(Dense(nb_classes, activation='softmax'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naval-framing",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Voir Modele 1 dans Backup pour voir le modèle initial du papier scientifique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "central-decade",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_frames = int(fps*2.4)\n",
    "\n",
    "if model_charge:\n",
    "    print('Modele chargé')\n",
    "    model = model_saved\n",
    "else:\n",
    "    print(\"Pas de modele chargé, il faut en créer un nouveau\")\n",
    "    #model = create_model(n_frames = n_frames, height = size[1], width = size[0], nb_classes = nb_classes)\n",
    "    model = create_simpler_model(n_frames = n_frames, height = size[1], width = size[0], nb_classes = nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "twelve-danish",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "central-shepherd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_name = folder + '\\\\images\\\\' +modele_type + param + '_plot.png'\n",
    "plot_model(model, to_file = plot_name, show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "resistant-model",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compilation\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(lr=learning_rate),\n",
    "              loss = tf.keras.losses.categorical_crossentropy,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bridal-oriental",
   "metadata": {},
   "source": [
    "##### Chargement d'un modele préentrainé (par nous même)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statutory-syntax",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_stolen_saved = keras.models.load_model('Saved_model\\\\modele_stolen_compile')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "selected-weather",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "interim-league",
   "metadata": {},
   "source": [
    "## Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "appropriate-redhead",
   "metadata": {},
   "outputs": [],
   "source": [
    "def homemade_fit_gen_thread(model, labels_val,pack_size,epochs,batch_size,fps = 5,size = (160,120)):\n",
    "    '''\n",
    "    Charge les données à partir du csv labels_val et train le model avec\n",
    "    les différents paramètres\n",
    "    Le model est train.\n",
    "    \n",
    "    Si besoin, return de X,y et model (mais normalement le model original est train)\n",
    "    '''\n",
    "    \n",
    "    #Histories de train ou de batch_loss au choix \n",
    "    histories = []\n",
    "    \n",
    "    t = threading.Thread(target = gen_thread, daemon = True,#Daemon afin que le thread s'arrête avec le thread principal\n",
    "                        args = ((labels_val, \"DATA\\\\Videos\",pack_size,fps, size))) \n",
    "    t.start()\n",
    "    while True:\n",
    "        X, y_num = q.get()\n",
    "        print(\"I got the pack! I'm going to fit it\")\n",
    "        print()\n",
    "        #Catégorisation pour train\n",
    "        y = to_categorical(y_num, num_classes = nb_classes)\n",
    "        \n",
    "        \n",
    "        start_fit = time()\n",
    "        history = model.fit(X, y,\n",
    "                batch_size = batch_size,\n",
    "                epochs=epochs,\n",
    "                verbose=1,\n",
    "                validation_split=0.1)  #Dans le fond je m'en fous un peu de cb je prend pour test\n",
    "        end_fit = time()\n",
    "        \n",
    "        histories.append(history)\n",
    "        print(f\"J'ai fini de train le paquet, ça m'a prit {end_fit - start_fit} secondes\")\n",
    "        q.task_done() #Jsp si c'est utile\n",
    "        \n",
    "        #Il faut que le fit prenne plus de temps que le chargement des vidéos, sinon ça va pas aller\n",
    "        \n",
    "        if q.empty():\n",
    "            print(\"J'ai peut-être fini, j'attends encore qq sec pour être sur d'avoir bien fini\")\n",
    "            sleep(20) #Je m'assure que c'est vraiment bien fini\n",
    "            if q.empty():\n",
    "                print(\"J'ai vraiment fini\")\n",
    "                break\n",
    "            else:\n",
    "                print(\"Je n'avais pas fini en fait\")\n",
    "    \n",
    "    t.join() #Je m'assure que le thread soit bien fini. \n",
    "    #Si il n'est pas fini, on plante. S'il avait fini, alors ça ne servait à rein\n",
    "    \n",
    "    del X\n",
    "    del y\n",
    "    del y_num\n",
    "    \n",
    "    return model, histories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intermediate-prospect",
   "metadata": {},
   "outputs": [],
   "source": [
    "def homemade_fit_gen(model, labels_val,pack_size,epochs,batch_size,fps = 5,size = (160,120)):\n",
    "    '''\n",
    "    Charge les données à partir du csv labels_val et train le model avec\n",
    "    les différents paramètres\n",
    "    Le model est train.\n",
    "    \n",
    "    my_gen et fit tournent en parallèle grâce à un thread\n",
    "    Si besoin, return de X,y et model (mais normalement le model original est train)\n",
    "    '''\n",
    "    \n",
    "    histories = []\n",
    "    \n",
    "    pointer = 0\n",
    "    can_continue = True\n",
    "    \n",
    "    while can_continue:\n",
    "        X, y_num, pointer = my_gen(labels_val, \"DATA\\\\Videos\",pack_size = pack_size,fps = fps, size = size, pointer = pointer)\n",
    "        \n",
    "        #Catégorisation pour train\n",
    "        y = to_categorical(y_num, num_classes = nb_classes)\n",
    "        \n",
    "        if pointer >= len(labels_val):\n",
    "            can_continue = False\n",
    "        print()\n",
    "\n",
    "        #print('vidéos chargées, shape:',X.shape,'. y len : ',len(y_num)) #DEBUG\n",
    "#         with tf.device('cpu:0'):\n",
    "#             history = model.fit(X, y,\n",
    "#                     batch_size = batch_size,\n",
    "#                     epochs=epochs,\n",
    "#                     verbose=1,\n",
    "#                     validation_split=0.2,\n",
    "#                     callbacks = [tensorboard])\n",
    "#         histories.append(history)\n",
    "        \n",
    "        #Suppression des variables qui ne sont plus utiles pour libérer de la mémoire\n",
    "        del X\n",
    "        del y\n",
    "        del y_num\n",
    "    return model, histories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "irish-uzbekistan",
   "metadata": {},
   "source": [
    "## Import des données et traitement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quiet-lebanon",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import des labels\n",
    "labels_csv = pd.read_csv(\"DATA\\\\labels.csv\")\n",
    "labels_name = pd.read_csv(\"DATA\\\\labels_uses.csv\")\n",
    "labels_tests_csv = pd.read_csv(\"DATA\\\\labels_tests.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alpine-organization",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Créé un dictionnaire qui associe le nom du label et un numérique afin de le mettre dans le modele\n",
    "labels_n = {}\n",
    "for i,label in enumerate(labels_name.values):\n",
    "    labels_n[label[0]] = i\n",
    "    labels_n[i] = label[0]\n",
    "\n",
    "    \n",
    "#Trier les labels pour ne prendre que ceux qui correspondent à labels_uses\n",
    "labels = []\n",
    "for label, video_name in labels_csv.values:\n",
    "    if label in labels_n:\n",
    "        labels.append((label,video_name))\n",
    "\n",
    "#Idem pour le label de tests\n",
    "labels_tests = []\n",
    "for label, video_name in labels_tests_csv.values:\n",
    "    if label in labels_n:\n",
    "        labels_tests.append((label,video_name))\n",
    "\n",
    "\n",
    "#Melange la liste de train\n",
    "for j in range(5):\n",
    "    random.shuffle(labels) #Il faut absolument shuffle pour train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "uniform-regard",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Count de chaque label\n",
    "labels_c = {}\n",
    "for label in labels_name.values:\n",
    "    labels_c[label[0]] = 0\n",
    "\n",
    "for label,video_name in labels:\n",
    "    if label in labels_c:\n",
    "        labels_c[label] += 1\n",
    "\n",
    "print(labels_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sudden-contemporary",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sunset-romania",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = Queue(maxsize = 1) #Variable globale nécessaire pour le bon fonctionnement du gen en thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "significant-insight",
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_charge:\n",
    "    print('Il ne faut pas train le modele car il a déjà été chargé')\n",
    "else:\n",
    "    print('Il faut entrainer le modele')\n",
    "    start = time()\n",
    "    with tf.device('cpu:0'):\n",
    "        model, histories = homemade_fit_gen_thread(model, labels, pack_size = pack_size,\n",
    "                                                        epochs = epochs,batch_size = batch_size,\n",
    "                                                        fps = fps, size = size)\n",
    "    end = time()\n",
    "    print(f\"ça a prit {end-start} secondes d'entrainer le modele\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "random-nebraska",
   "metadata": {},
   "source": [
    "### Amélioration du graphes au fur et à mesure du temps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "union-nerve",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pour l'histories de fit\n",
    "if not model_charge:\n",
    "    acc_plot = [hist.history['accuracy'] for hist in histories]\n",
    "    loss_plot = [hist.history['loss'] for hist in histories]\n",
    "    val_acc_plot = [hist.history['val_accuracy'] for hist in histories]\n",
    "    val_loss_plot = [hist.history['val_loss'] for hist in histories]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stuffed-dealer",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not model_charge: plt.plot(acc_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proper-poultry",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not model_charge: plt.plot(loss_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cloudy-rubber",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not model_charge: plt.plot(val_acc_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "every-documentary",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not model_charge: plt.plot(val_loss_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "european-difference",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_saved = keras.models.load_model(\"Saved_model\\\\model_convLSTM2D_10_10_75_100_10_1_20_40_1mili.h5\")\n",
    "model_saved = keras.models.load_model(\"Modele_acc77_bon.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "timely-formula",
   "metadata": {},
   "source": [
    "## Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collect-defensive",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test, _ = my_gen(labels_tests, \"DATA\\\\V_tests\",pack_size = 1000,fps = fps, size = size)\n",
    "#Grand pack_size afin de prendre toutes les données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "green-reynolds",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('cpu:0'):\n",
    "    start_pred = time()\n",
    "    y_pred = model_saved.predict(X_test)\n",
    "    end_pred = time()\n",
    "    print(f\"La prédiction prend {end_pred - start_pred} secondes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amazing-maintenance",
   "metadata": {},
   "source": [
    "## Affichage d'une video avec la prédiction pour comprendre si le résultat est justifié ou non"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continental-manufacturer",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,60)) #(20,60) pour des images en (120,160). (20,180) pour des images en (480,640)\n",
    "#print(X_test.shape)\n",
    "#Visu des mouvements avec une petite size (en fonction des paramètres initiaux)\n",
    "columns = 3\n",
    "vid_a_test = 3\n",
    "print(\"original:\",labels_n[y_test[vid_a_test]])\n",
    "print(\"prediction:\",labels_n[y_pred[vid_a_test].argmax()])\n",
    "for i, img in enumerate(X_test[vid_a_test]):\n",
    "    plt.subplot(int(len(img) / columns + 1), columns, i + 1)\n",
    "    plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pretty-muscle",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "hidden-murder",
   "metadata": {},
   "source": [
    "### visualisation des  résultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecological-deployment",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fidle.pwk as pwk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "passing-ranch",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "centered-honey",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_arg = np.argmax(y_pred, axis=-1)\n",
    "#plot_confusion_name = full_name + '_confusion.png'\n",
    "cfm_plot = pwk.plot_confusion_matrix(y_test,y_pred_arg,range(nb_classes),normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "artificial-budapest",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('cpu:0'):\n",
    "    y_test_cat = to_categorical(y_test,10)\n",
    "    score = model.evaluate(X_test, y_test_cat, verbose=1)\n",
    "\n",
    "print('Test loss     :', score[0])\n",
    "print('Test accuracy :', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "involved-lancaster",
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "manufactured-cholesterol",
   "metadata": {},
   "outputs": [],
   "source": [
    "#On vérifie que les résultats sont normalisé\n",
    "for result in y_pred:\n",
    "    #print('la somme est:',sum(result))\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "engaging-proof",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(labels_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fancy-geology",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Je peux afficher l'historique de chaque étape (je n'ai aps réussi à les faire fusionner)\n",
    "#On ne peut afficher que si on a train\n",
    "\n",
    "#history = histories[-1]\n",
    "#pwk.plot_history(history, figsize=(6,4), save_as='03-history')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greenhouse-converter",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compte le nombre de bons et de mauvais qu'on a ainsi que la moyenne,\n",
    "curseur  = 0.0 #curseur de 0 pour avoir tous les résultats\n",
    "count_good = 0\n",
    "to_mean_good = 0\n",
    "count_bad = 0\n",
    "to_mean_bad = 0\n",
    "for i,pred in enumerate(y_pred):\n",
    "    #Curseur\n",
    "    if np.max(pred) < curseur:\n",
    "        continue\n",
    "    if np.argmax(pred) == y_test[i]:\n",
    "        count_good += 1\n",
    "        to_mean_good += max(pred)\n",
    "    else:\n",
    "        count_bad +=1\n",
    "        to_mean_bad += max(pred)\n",
    "if count_good != 0:\n",
    "    mean_good = to_mean_good/count_good\n",
    "else: mean_good = 0\n",
    "if count_bad != 0:\n",
    "    mean_bad = to_mean_bad /count_bad\n",
    "else: mean_bad = 0\n",
    "print(\"Nombre de bon :\", count_good,\" Moyenne :\",mean_good)\n",
    "print(\"Nombre de mauvais :\",count_bad, \" Moyenne :\",mean_bad)\n",
    "#On constate que le modèle est souvent très sûr de ce qu'il avance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "precise-christmas",
   "metadata": {},
   "source": [
    "## Enregistrer le modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bibliographic-bolivia",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Le nom est fabriqué en début de notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "careful-congo",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "metallic-feelings",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "normal-layer",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Enregistrement du résultat dans le csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "injured-politics",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_score(model_name,score):\n",
    "    labels = open(\"Saved_model\\\\score.csv\",\"a\") #append\n",
    "    labels.write(\"\\n\" + model_name + \",\" + \"{:10.8f}\".format(score[0]) + \",\" + \"{:10.8f}\".format(score[1]))\n",
    "    #Ajoute une nouvelle info sur une nouvelle ligne\n",
    "    labels.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spoken-behavior",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(full_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "connected-fleece",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM, 5 FPS, Height = 60, Width = 80, nb_Classes = 10, 3 Epochs, Batch_size = 10, Pack_size = 50, learning_rate *1000\n",
    "if not model_charge: #On ne doit charger le modele que si il a été train cette fois-ci\n",
    "    write_score(full_name,score)\n",
    "    model.save(full_name+\".h5\")\n",
    "    model.save(full_name) #Plutôt deux fois q'une"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
