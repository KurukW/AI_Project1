{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "excited-infrastructure",
   "metadata": {},
   "source": [
    "# Modele de réseau neuronale"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interior-sugar",
   "metadata": {},
   "source": [
    "Toutes les étapes pour arriver à un modele correct"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "removable-thread",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "south-elder",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "In C:\\Users\\nicol\\anaconda3\\envs\\DL3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The text.latex.preview rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\nicol\\anaconda3\\envs\\DL3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The mathtext.fallback_to_cm rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\nicol\\anaconda3\\envs\\DL3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: Support for setting the 'mathtext.fallback_to_cm' rcParam is deprecated since 3.3 and will be removed two minor releases later; use 'mathtext.fallback : 'cm' instead.\n",
      "In C:\\Users\\nicol\\anaconda3\\envs\\DL3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The validate_bool_maybe_none function was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\nicol\\anaconda3\\envs\\DL3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The savefig.jpeg_quality rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\nicol\\anaconda3\\envs\\DL3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The keymap.all_axes rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\nicol\\anaconda3\\envs\\DL3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The animation.avconv_path rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\nicol\\anaconda3\\envs\\DL3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The animation.avconv_args rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "#import seaborn as sns #On ne sait jamais que ça serve\n",
    "import pandas as pd \n",
    "from sklearn.preprocessing import MinMaxScaler #Normalisation #Il faut l'installer aussi avec conda install\n",
    "import random\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, Sequential\n",
    "from tensorflow.keras.layers import  Dense, Conv3D, BatchNormalization,MaxPooling3D, Dropout, LSTM, ConvLSTM2D\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "\n",
    "\n",
    "#conda install pydot\n",
    "#conda install pydotplus\n",
    "#conda install graphviz\n",
    "from tensorflow.keras.utils import plot_model\n",
    "#import pydot\n",
    "\n",
    "\n",
    "import threading\n",
    "from queue import Queue, Empty\n",
    "from time import sleep, time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "present-blink",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "official-physiology",
   "metadata": {},
   "source": [
    "### Paramètres généraux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "monetary-error",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_classes = 10 #Nombre de classes\n",
    "fps = 5\n",
    "size = (40,30) #(40,30)\n",
    "#Parametres du generator\n",
    "pack_size = 50\n",
    "batch_size = 50\n",
    "epochs = 10 #20\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "corresponding-courage",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved_model\\model_convLSTM2D_5_30_40_10_10_50_50_1mili\n"
     ]
    }
   ],
   "source": [
    "#Verification qu'un modele avec ces paramètres n'existe pas déjà\n",
    "folder = 'Saved_model'\n",
    "modele_type = 'model_convLSTM2D'\n",
    "param = f\"_{fps}_{size[1]}_{size[0]}_{nb_classes}_{epochs}_{batch_size}_{pack_size}_{int(learning_rate*1000)}mili\"\n",
    "full_name = folder + '\\\\' + modele_type + param\n",
    "print(full_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "weekly-longer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modele non testé\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    model_saved = keras.models.load_model(full_name)\n",
    "    print(\"Pas besoin d'aller plus loin, le modele a déjà été fabriqué\")\n",
    "    model_charge = True\n",
    "except:\n",
    "    print(\"Modele non testé\")\n",
    "    model_charge = False\n",
    "    #Enregistrement sur Tensorboard\n",
    "    tensorboard = TensorBoard(log_dir='Saved_model\\\\logs\\\\{}'.format(full_name),)\n",
    "    #Il faut ouvrir la commande dans le dossier Saved_model et taper:\n",
    "    #tensorboard --logdir = logs/\n",
    "    #Ensuite un browser s'ouvre, et sinon on a une URL à mettre dessus\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "powerful-actor",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "hungarian-background",
   "metadata": {},
   "source": [
    "## Fonctions d'imports et preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "veterinary-clinton",
   "metadata": {},
   "source": [
    "#### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "visible-journalist",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mov_imgs_from_path(path,fps = -1,color = 'gray'):\n",
    "    '''\n",
    "    Retourne une liste d'images pour une vidéo. La liste d'image a le nombre de fps voulu\n",
    "    reprend que le mouvement\n",
    "    '''\n",
    "    \n",
    "    cap = cv2.VideoCapture(path)\n",
    "    fps_actu = cap.get(cv2.CAP_PROP_FPS)\n",
    "#     print(f\"Traitement de la video n° {path}       \",end=\"\\r\")\n",
    "    if fps <= -1: fps = fps_actu #Je peux ne pas donner de fps et ça va prendre le nombre d'fps initial\n",
    "    ecart_voulu = int(1000/fps)\n",
    "    ecart_initial = int(1000/fps_actu)\n",
    "    imgs = []\n",
    "    \n",
    "    ret, frame = cap.read()\n",
    "    while(cap.isOpened()):\n",
    "        prev = frame\n",
    "        ret, frame = cap.read()\n",
    "       \n",
    " \n",
    "        \n",
    "        if ret: #Sinon ça plante quand il n'y a plus d'images\n",
    "            #Récupère seulement certaines images\n",
    "            t_ms = cap.get(cv2.CAP_PROP_POS_MSEC)\n",
    "            modulo = t_ms % ecart_voulu\n",
    "            if modulo < ecart_initial:\n",
    "                #Isoler les images\n",
    "                \n",
    "                if color == 'gray':\n",
    "                    gray = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "                    prev_gray = cv2.cvtColor(prev,cv2.COLOR_BGR2GRAY)\n",
    "                    diff_gray = cv2.absdiff(gray,prev_gray)\n",
    "                    \n",
    "                elif color == 'rgb':\n",
    "                    diff_gray = cv2.absdiff(frame,prev) \n",
    "\n",
    "                    \n",
    "                #Première normalisation (elle n'est peut-être pas obligatoire)\n",
    "                max_ = np.max(diff_gray)\n",
    "                if max_ == 0:\n",
    "                    max_ = 1\n",
    "                ratio = 255.0 / max_\n",
    "                diff_gray = diff_gray * ratio\n",
    "                \n",
    "                \n",
    "                #On va travailler avec des images en nuance de gris, c'est bcp plus simple\n",
    "                imgs.append(diff_gray)\n",
    "            \n",
    "        else: #Va jusqu'au bout de la vidéo\n",
    "            break\n",
    "    else:\n",
    "        print(\"Le fichier n'a pas pu être ouvert\")\n",
    "    cap.release()\n",
    "    \n",
    "    return imgs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "casual-gazette",
   "metadata": {},
   "source": [
    "#### Resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "front-dragon",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_imgs(imgs,nsize):\n",
    "    '''\n",
    "    Change la taille de l'image.\n",
    "    Le premier élément de nsize est la longueur (width), le deuxième la hauteur (height)\n",
    "    '''\n",
    "    return [cv2.resize(img, dsize=nsize, interpolation=cv2.INTER_CUBIC) for img in imgs]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thick-beaver",
   "metadata": {},
   "source": [
    "#### Normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "stuffed-cinema",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_by_pixels(img, x_min, x_max):\n",
    "    '''\n",
    "    Scale une image entre 0 et 1.\n",
    "    Méthode pas efficace mais fonctionnelle contrairement à d'autres méthodes \n",
    "    qui faisaient lignes par lignes ce qui causait des erreurs \n",
    "    dans le résultat (lignes dans l'image)\n",
    "    '''\n",
    "    new_img = img.copy()\n",
    "    p_min = 1000\n",
    "    p_max = -1000\n",
    "    for line in img:\n",
    "        for pixel in line:\n",
    "            p_min = min(p_min,pixel)\n",
    "            p_max = max(p_max,pixel)\n",
    "    \n",
    "    #p_min et p_max sont les min et max totaux de mon image\n",
    "    for l, line in enumerate(img):\n",
    "        for p,pixel in enumerate(line):\n",
    "            nom = (pixel - p_min)*(x_max - x_min)\n",
    "            denom = (p_max - p_min)\n",
    "            if denom == 0: denom = 1\n",
    "            new_img[l][p] = x_min + nom/denom\n",
    "    return new_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "resident-communication",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_imgs(imgs):\n",
    "    '''\n",
    "    Normalise une série d'images\n",
    "    '''\n",
    "    norm_imgs = []\n",
    "    for img in imgs:\n",
    "        norm_img = scale_by_pixels(img,0,1)\n",
    "        norm_imgs.append(norm_img)\n",
    "#     print(f\"Après normalisation, max = {np.max(norm_imgs)} et min = {np.min(norm_imgs)}\")\n",
    "    return norm_imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regulated-theory",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "powerful-compromise",
   "metadata": {},
   "source": [
    "## Fonction de générateur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "secret-hollow",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_gen(labels_list, folder_path, pack_size = 10, pointer = 0, fps = 5, size = (160,120)):\n",
    "    '''\n",
    "    à partir de la liste des labels et de la position du foler\n",
    "    Retourne:\n",
    "    -une liste d'images de vidéos de shape (pack_size,n_frames,height,width[,channels])\n",
    "        n_frames = fps*2.4\n",
    "    -Une liste de numérique avec les labels correspondant aux images (de len = batch_size)\n",
    "    -Un pointer qui permet de faire tourner my_gen à nouveau et recevoir les éléments suivants de la liste\n",
    "    \n",
    "    \n",
    "    Normalement on peut envoyer X et y_num dans le modele directement (avec fit ou train_on_batch, les deux devraient fonctionner)\n",
    "    Je vais essayer de travailler avec des thread pour avoir un thread en Train et un trhead en gen\n",
    "    '''\n",
    "    \n",
    "    y_num = []\n",
    "    X = []\n",
    "    for i in range(pointer, pack_size + pointer):\n",
    "        pointer = i+1\n",
    "        if i >= len(labels_list):\n",
    "            break\n",
    "        label, video_name = labels_list[i]\n",
    "        \n",
    "        #Label en numérique\n",
    "        y_num.append(labels_n[label])\n",
    "        \n",
    "        #Preprocess d'images\n",
    "        file_path = folder_path + \"\\\\\" + video_name\n",
    "        imgs_of_video = get_mov_imgs_from_path(file_path,fps,'gray') #Gray ou rgb\n",
    "        resized_imgs = resize_imgs(imgs_of_video, size)\n",
    "        norm_imgs = normalize_imgs(resized_imgs)\n",
    "        \n",
    "        X.append(norm_imgs)\n",
    "        \n",
    "    print() #Pour ne pas écrire sur la même ligne qu'avant\n",
    "    X = np.array(X)\n",
    "    y = np.array(y_num)\n",
    "    \n",
    "    #Ajouter une dimsension en à la fin est nécessaire pour certains modèle\n",
    "    #Commenter cette ligne si ce n'est pas nécessaire\n",
    "    X = np.expand_dims(X, axis=len(X.shape)) \n",
    "    \n",
    "    # Si le modele est compile avec :loss='sparse_categorical_crossentropy'\n",
    "    # Il faut un y catégorique , faire ça hors de la fonction\n",
    "    #y = to_categorical(y, num_classes = nb_classes)\n",
    "\n",
    "    return (X, y, pointer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "inner-palestine",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_thread(labels_list, folder_path, pack_size = 10, fps = 5, size = (160,120)):\n",
    "    '''\n",
    "    S'assure que my_gen tourne toujours en parallèle du fit. Il prépare toujours 2 paquets de vidéo en avance\n",
    "    '''\n",
    "    pointer = 0\n",
    "    while pointer < 150:#< len(labels_list):\n",
    "        X,y,pointer = my_gen(labels_list, folder_path, pack_size, pointer, fps, size)\n",
    "        q.put((X,y))\n",
    "        print(f\"Pack of {pack_size} videos put in queue\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affected-undergraduate",
   "metadata": {},
   "source": [
    "## Fabrication des modeles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "possible-representative",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "civic-insert",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "matched-genealogy",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(n_frames = 24, height = 120, width = 160, channels = 1, nb_classes = 10):\n",
    "    \n",
    "    \n",
    "    #Dernière couche avant reshape\n",
    "    last_channel = 16\n",
    "    \n",
    "    #Gestion de la hauteur et la width:\n",
    "    output_shape = int(height/27) * int(width/27) * last_channel\n",
    "    \n",
    "    #Divisé par 27 parce qu'on divise par 3, 3 fois (avec Maxpooling)\n",
    "\n",
    "    \n",
    "    sample_shape = (n_frames,height,width,channels) #width = 160, height = 120, nframes = 24, 3 channels si on est en RGB (si on est en gris on sait pas)\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    #model.add(Conv3D(128, strides =(1,1,1), padding=\"same\", kernel_size=(3, 3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=sample_shape,data_format='channels_first'))\n",
    "    model.add(Conv3D(192, strides =(1,1,1), padding=\"same\", kernel_size=(3, 3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=sample_shape,data_format='channels_last'))\n",
    "    model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(BatchNormalization(center=True, scale=True))\n",
    "    model.add(Conv3D(96, strides=(1,1,1), padding=\"same\", kernel_size=(3, 3, 3), activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(BatchNormalization(center=True, scale=True))\n",
    "    model.add(MaxPooling3D(pool_size=(3, 3, 3), data_format = 'channels_first'))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Conv3D(96, strides=(1,1,1), padding=\"same\", kernel_size=(3, 3, 3), activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(Dense(96, activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(BatchNormalization(center=True, scale=True))\n",
    "    model.add(Conv3D(64, strides=(1,1,1), padding=\"same\", kernel_size=(3, 3, 3), activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(Dense(64, activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(BatchNormalization(center=True, scale=True))\n",
    "    model.add(MaxPooling3D(pool_size=(2, 2, 2), data_format = 'channels_first'))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Conv3D(48, strides=(1,1,1), padding=\"same\", kernel_size=(3, 3, 3), activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(Dense(48, activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(BatchNormalization(center=True, scale=True))\n",
    "    model.add(Conv3D(32, strides=(1,1,1), padding=\"same\", kernel_size=(3, 3, 3), activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(Dense(32, activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(BatchNormalization(center=True, scale=True))\n",
    "    model.add(MaxPooling3D(pool_size=(2,2, 2), data_format = 'channels_first')) #Je ne veux pas diviser le nombre d'images cette fois-ci\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Conv3D(last_channel, strides=(1,1,1), padding=\"same\", kernel_size=(3, 3, 3), activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(Dense(last_channel, activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(BatchNormalization(center=True, scale=True))\n",
    "\n",
    "\n",
    "\n",
    "    #LSTM\n",
    "    \n",
    "    model.add(ConvLSTM2D(filters = 64,kernel_size = (2,2),activation=\"tanh\", recurrent_activation=\"sigmoid\",return_sequences = False))\n",
    "    model.add(layers.Reshape((128,)))\n",
    "    #model.add(ConvLSTM2D(filters = 64,kernel_size = (1,1),activation=\"tanh\", recurrent_activation=\"sigmoid\",return_sequences = False))\n",
    "    \n",
    "\n",
    "    #softmax\n",
    "    model.add(Dense(nb_classes, activation='softmax'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "structural-gasoline",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pas de modele chargé, il faut en créer un nouveau\n"
     ]
    }
   ],
   "source": [
    "n_frames = int(fps*2.4)\n",
    "\n",
    "if model_charge:\n",
    "    print('Modele chargé')\n",
    "    model = model_saved\n",
    "else:\n",
    "    print(\"Pas de modele chargé, il faut en créer un nouveau\")\n",
    "    model = create_model(n_frames = n_frames, height = size[1], width = size[0], nb_classes = nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ruled-trash",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d (Conv3D)              (None, 12, 30, 40, 192)   5376      \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 12, 30, 40, 128)   24704     \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 12, 30, 40, 128)   512       \n",
      "_________________________________________________________________\n",
      "conv3d_1 (Conv3D)            (None, 12, 30, 40, 96)    331872    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 12, 30, 40, 128)   12416     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 12, 30, 40, 128)   512       \n",
      "_________________________________________________________________\n",
      "max_pooling3d (MaxPooling3D) (None, 12, 10, 13, 42)    0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 12, 10, 13, 42)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_2 (Conv3D)            (None, 12, 10, 13, 96)    108960    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 12, 10, 13, 96)    9312      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 12, 10, 13, 96)    384       \n",
      "_________________________________________________________________\n",
      "conv3d_3 (Conv3D)            (None, 12, 10, 13, 64)    165952    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 12, 10, 13, 64)    4160      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 12, 10, 13, 64)    256       \n",
      "_________________________________________________________________\n",
      "max_pooling3d_1 (MaxPooling3 (None, 12, 5, 6, 32)      0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 12, 5, 6, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv3d_4 (Conv3D)            (None, 12, 5, 6, 48)      41520     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 12, 5, 6, 48)      2352      \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 12, 5, 6, 48)      192       \n",
      "_________________________________________________________________\n",
      "conv3d_5 (Conv3D)            (None, 12, 5, 6, 32)      41504     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 12, 5, 6, 32)      1056      \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 12, 5, 6, 32)      128       \n",
      "_________________________________________________________________\n",
      "max_pooling3d_2 (MaxPooling3 (None, 12, 2, 3, 16)      0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 12, 2, 3, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv3d_6 (Conv3D)            (None, 12, 2, 3, 16)      6928      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 12, 2, 3, 16)      272       \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 12, 2, 3, 16)      64        \n",
      "_________________________________________________________________\n",
      "conv_lst_m2d (ConvLSTM2D)    (None, 1, 2, 64)          82176     \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 841,898\n",
      "Trainable params: 840,874\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "following-riding",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Failed to import pydot. You must `pip install pydot` and install graphviz (https://graphviz.gitlab.io/download/), ', 'for `pydotprint` to work.')\n"
     ]
    }
   ],
   "source": [
    "plot_name = full_name + '_plot.png'\n",
    "plot_model(model, to_file = plot_name, show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "demonstrated-jordan",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compilation\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(lr=learning_rate),\n",
    "              loss = tf.keras.losses.categorical_crossentropy,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mexican-bicycle",
   "metadata": {},
   "source": [
    "##### Chargement d'un modele préentrainé (par nous même)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "small-workplace",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_stolen_saved = keras.models.load_model('Saved_model\\\\modele_stolen_compile')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tropical-monitor",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "caring-technology",
   "metadata": {},
   "source": [
    "## Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "scientific-methodology",
   "metadata": {},
   "outputs": [],
   "source": [
    "def homemade_fit_gen_thread(model, labels_val,pack_size,epochs,batch_size,fps = 5,size = (160,120)):\n",
    "    '''\n",
    "    Charge les données à partir du csv labels_val et train le model avec\n",
    "    les différents paramètres\n",
    "    Le model est train.\n",
    "    \n",
    "    Si besoin, return de X,y et model (mais normalement le model original est train)\n",
    "    '''\n",
    "#     q = Queue()\n",
    "    \n",
    "    #Histories de train ou de batch_loss au choix \n",
    "    histories = []\n",
    "    \n",
    "    t = threading.Thread(target = gen_thread, daemon = True,#Daemon afin que le thread s'arrête avec le thread principal\n",
    "                        args = ((labels_val, \"DATA\\\\Videos\",pack_size,fps, size))) \n",
    "    t.start()\n",
    "    while True:\n",
    "        X, y_num = q.get()\n",
    "        print(\"I got the pack! I'm going to fit it\")\n",
    "        print()\n",
    "        #Catégorisation pour train\n",
    "        y = to_categorical(y_num, num_classes = nb_classes)\n",
    "        \n",
    "#       batch_loss = model.train_on_batch(X,y)\n",
    "        history = model.fit(X, y,\n",
    "                batch_size = batch_size,\n",
    "                epochs=epochs,\n",
    "                verbose=1,\n",
    "                validation_split=0.2,\n",
    "                callbacks = [tensorboard])\n",
    "        #histories.append(batch_loss)\n",
    "        histories.append(history)\n",
    "        print(\"J'ai fini de train le paquet\")\n",
    "        q.task_done() #Jsp si c'est utile\n",
    "        \n",
    "        #Il faut que le fit prenne plus de temps que le chargement des vidéos, sinon ça va pas aller\n",
    "        \n",
    "        if q.empty():\n",
    "            print(\"J'ai peut-être fini, j'attends encore qq sec pour être sur d'avoir bien fini\")\n",
    "            sleep(20) #Je m'assure que c'est vraiment bien fini\n",
    "            if q.empty():\n",
    "                print(\"J'ai vraiment fini\")\n",
    "                break\n",
    "            else:\n",
    "                print(\"Je n'avais pas fini en fait\")\n",
    "    \n",
    "    t.join() #Je m'assure que le thread soit bien fini. \n",
    "    #Si il n'est pas fini, on plante. S'il avait fini, alors ça ne servait à rein\n",
    "    \n",
    "    del X\n",
    "    del y\n",
    "    del y_num\n",
    "    \n",
    "    return model, histories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "complimentary-familiar",
   "metadata": {},
   "outputs": [],
   "source": [
    "def homemade_fit_gen(model, labels_val,pack_size,epochs,batch_size,fps = 5,size = (160,120)):\n",
    "    '''\n",
    "    Charge les données à partir du csv labels_val et train le model avec\n",
    "    les différents paramètres\n",
    "    Le model est train.\n",
    "    \n",
    "    my_gen et fit tournent en parallèle grâce à un thread\n",
    "    Si besoin, return de X,y et model (mais normalement le model original est train)\n",
    "    '''\n",
    "    \n",
    "    histories = []\n",
    "    \n",
    "    pointer = 0\n",
    "    can_continue = True\n",
    "    \n",
    "    while can_continue:\n",
    "        X, y_num, pointer = my_gen(labels_val, \"DATA\\\\Videos\",pack_size = pack_size,fps = fps, size = size, pointer = pointer)\n",
    "        \n",
    "        #Catégorisation pour train\n",
    "        y = to_categorical(y_num, num_classes = nb_classes)\n",
    "        \n",
    "        if pointer >= len(labels_val):\n",
    "            can_continue = False\n",
    "        print()\n",
    "\n",
    "        #print('vidéos chargées, shape:',X.shape,'. y len : ',len(y_num)) #DEBUG\n",
    "        with tf.device('cpu:0'):\n",
    "            history = model.fit(X, y,\n",
    "                    batch_size = batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.2,\n",
    "                    callbacks = [tensorboard])\n",
    "        histories.append(history)\n",
    "        \n",
    "        \n",
    "    return model, histories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "competitive-market",
   "metadata": {},
   "source": [
    "## Import des données et traitement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "physical-count",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import des labels\n",
    "labels_csv = pd.read_csv(\"DATA\\\\labels.csv\")\n",
    "labels_name = pd.read_csv(\"DATA\\\\labels_uses.csv\")\n",
    "labels_tests_csv = pd.read_csv(\"DATA\\\\labels_tests.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "surface-answer",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Créé un dictionnaire qui associe le nom du label et un numérique afin de le mettre dans le modele\n",
    "labels_n = {}\n",
    "for i,label in enumerate(labels_name.values):\n",
    "    labels_n[label[0]] = i\n",
    "    labels_n[i] = label[0]\n",
    "\n",
    "    \n",
    "#Trier les labels pour ne prendre que ceux qui correspondent à labels_uses\n",
    "labels = []\n",
    "for label, video_name in labels_csv.values:\n",
    "    if label in labels_n:\n",
    "        labels.append((label,video_name))\n",
    "        \n",
    "#Idem pour le label de tests\n",
    "labels_tests = []\n",
    "for label, video_name in labels_tests_csv.values:\n",
    "    if label in labels_n:\n",
    "        labels_tests.append((label,video_name))\n",
    "\n",
    "\n",
    "#Melange la liste de train\n",
    "random.shuffle(labels) #Il faut absolument shuffle pour train\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "southwest-champagne",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Ferme le poing': 57, 'Ouvre le poing': 60, 'Clap': 54, 'Swipe gauche main droite': 49, 'Swipe droit main gauche': 50, 'Doigts croises paumes': 51, 'Explosion avec les doigts ouverts': 53, 'Ouvrir un livre avec le poing ferme main D': 44, 'Ouvrir un livre avec le poing ferme main G': 39, 'Faire coucou': 64}\n"
     ]
    }
   ],
   "source": [
    "#Count de chaque label\n",
    "labels_c = {}\n",
    "for label in labels_name.values:\n",
    "    labels_c[label[0]] = 0\n",
    "\n",
    "for label,video_name in labels:\n",
    "    if label in labels_c:\n",
    "        labels_c[label] += 1\n",
    "\n",
    "print(labels_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collaborative-there",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "embedded-physiology",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = Queue(maxsize = 1) #Variable globale nécessaire pour le bon fonctionnement du gen en thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "accessory-ethics",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Il faut entrainer le modele\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'devices'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-93a8bc47abfa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m     model, histories = homemade_fit_gen(model, labels, pack_size = pack_size,\n\u001b[0;32m      7\u001b[0m                                                     \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m                                                     fps = fps, size = size)\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"ça a prit {end-start} secondes d'entrainer le modele\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-24-a7653e374a84>\u001b[0m in \u001b[0;36mhomemade_fit_gen\u001b[1;34m(model, labels_val, pack_size, epochs, batch_size, fps, size)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[1;31m#print('vidéos chargées, shape:',X.shape,'. y len : ',len(y_num)) #DEBUG\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevices\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'cpu:0'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m             history = model.fit(X, y,\n\u001b[0;32m     29\u001b[0m                     \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'devices'"
     ]
    }
   ],
   "source": [
    "if model_charge:\n",
    "    print('Il ne faut pas train le modele car il a déjà été chargé')\n",
    "else:\n",
    "    print('Il faut entrainer le modele')\n",
    "    start = time()\n",
    "    model, histories = homemade_fit_gen(model, labels, pack_size = pack_size,\n",
    "                                                    epochs = epochs,batch_size = batch_size,\n",
    "                                                    fps = fps, size = size)\n",
    "    end = time()\n",
    "    print(f\"ça a prit {end-start} secondes d'entrainer le modele\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "computational-breeding",
   "metadata": {},
   "source": [
    "### Amélioration du graphes au fur et à mesure du temps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "domestic-damages",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pour l'histories de fit\n",
    "if not model_charge:\n",
    "    acc_plot = [hist.history['accuracy'] for hist in histories]\n",
    "    loss_plot = [hist.history['loss'] for hist in histories]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "destroyed-journalism",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not model_charge: plt.plot(acc_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "finished-comment",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not model_charge: plt.plot(loss_plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "western-vinyl",
   "metadata": {},
   "source": [
    "## Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informative-accuracy",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test, _ = my_gen(labels_tests, \"DATA\\\\V_tests\",pack_size = 1000,fps = fps, size = size)\n",
    "#Grand pack_size afin de prendre toutes les données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assisted-gravity",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conscious-fashion",
   "metadata": {},
   "source": [
    "## Experience: Temp à supprimer dès que ça ne fait plus de sens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "needed-booking",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,60)) #(20,60) pour des images en (120,160). (20,180) pour des images en (480,640)\n",
    "#print(X_test.shape)\n",
    "#Visu des mouvements avec une petite size (en fonction des paramètres initiaux)\n",
    "columns = 3\n",
    "vid_a_test = 11\n",
    "print(\"original:\",labels_n[y_test[vid_a_test]])\n",
    "print(\"prediction:\",labels_n[y_pred[vid_a_test].argmax()])\n",
    "for i, img in enumerate(X_test[vid_a_test]):\n",
    "    plt.subplot(int(len(img) / columns + 1), columns, i + 1)\n",
    "    plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "manual-disposal",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "social-uzbekistan",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "human-singer",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "israeli-limitation",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "informed-broadcasting",
   "metadata": {},
   "source": [
    "### visualisation des  résultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "framed-paraguay",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fidle.pwk as pwk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "modern-hindu",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cardiac-depth",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_arg = np.argmax(y_pred, axis=-1)\n",
    "plot_confusion_name = full_name + '_confusion.png'\n",
    "cfm_plot = pwk.plot_confusion_matrix(y_test,y_pred_arg,range(nb_classes),normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interracial-domestic",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_cat = to_categorical(y_test,10)\n",
    "score = model.evaluate(X_test, y_test_cat, verbose=1)\n",
    "\n",
    "print('Test loss     :', score[0])\n",
    "print('Test accuracy :', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exact-rebel",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accredited-specification",
   "metadata": {},
   "outputs": [],
   "source": [
    "#On vérifie que les résultats sont normalisé\n",
    "for result in y_pred:\n",
    "    print('la somme est:',sum(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "steady-performer",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(labels_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "animal-apache",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Je peux afficher l'historique de chaque étape (je n'ai aps réussi à les faire fusionner)\n",
    "#On ne peut afficher que si on a train\n",
    "\n",
    "#history = histories[-1]\n",
    "#pwk.plot_history(history, figsize=(6,4), save_as='03-history')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stretch-pocket",
   "metadata": {},
   "source": [
    "## Enregistrer le modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "practical-duration",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Le nom est fabriqué en début de notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "protecting-split",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "retained-assurance",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "criminal-mileage",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Enregistrement du résultat dans le csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "large-accommodation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_score(model_name,score):\n",
    "    labels = open(\"Saved_model\\\\score.csv\",\"a\") #append\n",
    "    labels.write(\"\\n\" + model_name + \",\" + \"{:10.8f}\".format(score[0]) + \",\" + \"{:10.8f}\".format(score[1]))\n",
    "    #Ajoute une nouvelle info sur une nouvelle ligne\n",
    "    labels.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "employed-decade",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(full_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rolled-player",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM, 5 FPS, Height = 60, Width = 80, nb_Classes = 10, 3 Epochs, Batch_size = 10, Pack_size = 50, learning_rate *1000\n",
    "if not model_charge: #On ne doit charger le modele que si il a été train cette fois-ci\n",
    "    write_score(full_name,score)\n",
    "    model.save(full_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blank-tourist",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pleased-liabilities",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "colonial-aurora",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dominant-highlight",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "modified-uzbekistan",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gross-tolerance",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "closed-validity",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "preliminary-demand",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "graduate-request",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
