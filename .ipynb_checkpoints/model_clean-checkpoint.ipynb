{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eastern-swaziland",
   "metadata": {},
   "source": [
    "# Modele de réseau neuronale"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "harmful-oxford",
   "metadata": {},
   "source": [
    "Toutes les étapes pour arriver à un modele correct"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "middle-investigator",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "devoted-brunswick",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "#import seaborn as sns #On ne sait jamais que ça serve\n",
    "import pandas as pd \n",
    "from sklearn.preprocessing import MinMaxScaler #Normalisation\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attempted-console",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "raised-navigator",
   "metadata": {},
   "source": [
    "### Paramètres généraux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "smooth-victor",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_classes = 13 #Nombre de classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "civilian-thanks",
   "metadata": {},
   "source": [
    "## Fonctions d'imports et preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dressed-adult",
   "metadata": {},
   "source": [
    "#### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "normal-investigator",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mov_imgs_from_path(path,fps = -1,color = 'gray'):\n",
    "    '''\n",
    "    Retourne une liste d'images pour une vidéo. La liste d'image a le nombre de fps voulu\n",
    "    reprend que le mouvement\n",
    "    '''\n",
    "    \n",
    "    cap = cv2.VideoCapture(path)\n",
    "    fps_actu = cap.get(cv2.CAP_PROP_FPS)\n",
    "    print(f\"Traitement de la video n° {path}       \",end=\"\\r\")\n",
    "    if fps <= -1: fps = fps_actu #Je peux ne pas donner de fps et ça va prendre le nombre d'fps initial\n",
    "    ecart_voulu = int(1000/fps)\n",
    "    ecart_initial = int(1000/fps_actu)\n",
    "    imgs = []\n",
    "    \n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    while(cap.isOpened()):\n",
    "        prev = frame\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        if ret: #Sinon ça plante quand il n'y a plus d'images\n",
    "            #Récupère seulement certaines images\n",
    "            t_ms = cap.get(cv2.CAP_PROP_POS_MSEC)\n",
    "            modulo = t_ms % ecart_voulu\n",
    "            if modulo < ecart_initial:\n",
    "                #Isoler les images\n",
    "                \n",
    "                diff = cv2.absdiff(frame,prev)  \n",
    "                if color == 'gray':\n",
    "                    diff_gray = cv2.cvtColor(diff,cv2.COLOR_BGR2GRAY)\n",
    "                elif color == 'rgb':\n",
    "                    diff_gray = diff\n",
    "\n",
    "                    \n",
    "                #Première normalisation (elle n'est peut-être pas obligatoire)\n",
    "                max_ = np.max(diff_gray)\n",
    "                if max_ == 0:\n",
    "                    max_ = 1\n",
    "                ratio = 255.0 / max_\n",
    "                diff_gray = diff_gray * ratio\n",
    "                \n",
    "                \n",
    "                #On va travailler avec des images en nuance de gris, c'est bcp plus simple\n",
    "                imgs.append(diff_gray)\n",
    "            \n",
    "        else: #Va jusqu'au bout de la vidéo\n",
    "            break\n",
    "    else:\n",
    "        print(\"Le fichier n'a pas pu être ouvert\")\n",
    "    cap.release()\n",
    "    \n",
    "    return imgs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "durable-asset",
   "metadata": {},
   "source": [
    "#### Resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "copyrighted-precipitation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_imgs(imgs,nsize):\n",
    "    '''\n",
    "    Change la taille de l'image.\n",
    "    Le premier élément de nsize est la longueur (width), le deuxième la hauteur (height)\n",
    "    '''\n",
    "    return [cv2.resize(img, dsize=nsize, interpolation=cv2.INTER_CUBIC) for img in imgs]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "above-theta",
   "metadata": {},
   "source": [
    "#### Normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "checked-joining",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_by_pixels(img, x_min, x_max):\n",
    "    '''\n",
    "    Scale une image entre 0 et 1.\n",
    "    Méthode pas efficace mais fonctionnelle contrairement à d'autres méthodes \n",
    "    qui faisaient lignes par lignes ce qui causait des erreurs \n",
    "    dans le résultat (lignes dans l'image)\n",
    "    '''\n",
    "    new_img = img.copy()\n",
    "    p_min = 1000\n",
    "    p_max = -1000\n",
    "    for line in img:\n",
    "        for pixel in line:\n",
    "            p_min = min(p_min,pixel)\n",
    "            p_max = max(p_max,pixel)\n",
    "    \n",
    "    #p_min et p_max sont les min et max totaux de mon image\n",
    "    for l, line in enumerate(img):\n",
    "        for p,pixel in enumerate(line):\n",
    "            nom = (pixel - p_min)*(x_max - x_min)\n",
    "            denom = (p_max - p_min)\n",
    "            if denom == 0: denom = 1\n",
    "            new_img[l][p] = x_min + nom/denom\n",
    "    return new_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "stopped-billy",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_imgs(imgs):\n",
    "    '''\n",
    "    Normalise une série d'images\n",
    "    '''\n",
    "    norm_imgs = []\n",
    "    for img in imgs:\n",
    "        norm_img = scale_by_pixels(img,0,1)\n",
    "        norm_imgs.append(norm_img)\n",
    "#     print(f\"Après normalisation, max = {np.max(norm_imgs)} et min = {np.min(norm_imgs)}\")\n",
    "    return norm_imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recreational-federal",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "differential-shaft",
   "metadata": {},
   "source": [
    "## Fonction de générateur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "quality-bulgarian",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_gen(labels_list, folder_path, batch_size = 10, pointer = 0, fps = 5, size = (160,120)):\n",
    "    '''\n",
    "    à partir de la liste des labels et de la position du foler\n",
    "    Retourne:\n",
    "    -une liste d'images de vidéos de shape (batch_size,n_frames,height,width[,channels])\n",
    "        n_frames = fps*2.4\n",
    "    -Une liste de numérique avec les labels correspondant aux images (de len = batch_size)\n",
    "    -Un pointer qui permet de faire tourner my_gen à nouveau et recevoir les éléments suivants de la liste\n",
    "    \n",
    "    \n",
    "    Normalement on peut envoyer X et y_num dans le modele directement (avec fit ou train_on_batch, les deux devraient fonctionner)\n",
    "    Je vais essayer de travailler avec des thread pour avoir un thread en Train et un trhead en gen\n",
    "    '''\n",
    "    \n",
    "    y_num = []\n",
    "    X = []\n",
    "    for i in range(pointer, batch_size + pointer):\n",
    "        pointer = i+1\n",
    "        if i >= len(labels_list):\n",
    "            break\n",
    "        label, video_name = labels_list[i]\n",
    "        \n",
    "        #Label en numérique\n",
    "        y_num.append(labels_n[label])\n",
    "        \n",
    "        #Preprocess d'images\n",
    "        file_path = folder_path + \"\\\\\" + video_name\n",
    "        imgs_of_video = get_mov_imgs_from_path(file_path,fps,'gray') #Gray ou rgb\n",
    "        resized_imgs = resize_imgs(imgs_of_video, size)\n",
    "        norm_imgs = normalize_imgs(resized_imgs)\n",
    "        \n",
    "        X.append(norm_imgs)\n",
    "        \n",
    "    \n",
    "    X = np.array(X)\n",
    "    y = np.array(y_num)\n",
    "    \n",
    "    #Ajouter une dimsension en à la fin est nécessaire pour certains modèle\n",
    "    #Commenter cette ligne si ce n'est pas nécessaire\n",
    "    X = np.expand_dims(X, axis=len(X.shape)) \n",
    "    \n",
    "    # Si le modele est compile avec :loss='sparse_categorical_crossentropy'\n",
    "    # Il faut un y catégorique , faire ça hors de la fonction\n",
    "    #y = to_categorical(y, num_classes = nb_classes)\n",
    "\n",
    "    return (X, y, pointer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surprising-share",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "impaired-agent",
   "metadata": {},
   "source": [
    "## Fabrication des modeles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "disturbed-highlight",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "future-floor",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, Sequential\n",
    "from tensorflow.keras.layers import  Dense, Conv3D, BatchNormalization,MaxPooling3D, Dropout, LSTM\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "scenic-briefs",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Voir Model_experiences.ipynb pour les différents modeles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "rocky-gentleman",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creation du modele"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "capable-rendering",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compilation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "auburn-reliance",
   "metadata": {},
   "source": [
    "##### Chargement d'un modele préentrainé (par nous même)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "north-object",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_stolen_saved = keras.models.load_model('Saved_model\\\\modele_stolen_compile')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aquatic-valve",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fitted-studio",
   "metadata": {},
   "source": [
    "## Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "desperate-surgeon",
   "metadata": {},
   "outputs": [],
   "source": [
    "def homemade_fit_generator(model, labels_val,batch_size,epochs,fps = 5,size = (160,120)):\n",
    "    '''\n",
    "    Charge les données à partir du csv labels_val et train le model avec\n",
    "    les différents paramètres\n",
    "    Le model est train.\n",
    "    \n",
    "    Si besoin, return de X,y et model (mais normalement le model original est train)\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    pointer = 0\n",
    "    can_continue = True\n",
    "\n",
    "    while can_continue:\n",
    "        X, y_num, pointer = my_gen(labels_val, \"DATA\\\\Videos\",batch_size = batch_size,fps = fps, size = size, pointer = pointer)\n",
    "        \n",
    "        #Catégorisation pour train\n",
    "        y = to_categorical(y_num, num_classes = nb_classes)\n",
    "        \n",
    "        if pointer >= len(labels_val):\n",
    "            can_continue = False\n",
    "        print()\n",
    "\n",
    "        #print('vidéos chargées, shape:',X.shape,'. y len : ',len(y_num)) #DEBUG\n",
    "       \n",
    "        model.fit(X, y,\n",
    "                batch_size = 10,\n",
    "                epochs=2,\n",
    "                verbose=1,\n",
    "                validation_split=0.2)\n",
    "    return model, X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "completed-series",
   "metadata": {},
   "source": [
    "## Import des données et traitement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "abroad-currency",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import des labels\n",
    "labels_csv = pd.read_csv(\"DATA\\\\labels.csv\")\n",
    "labels_name = pd.read_csv(\"DATA\\\\labels_list.csv\")\n",
    "labels_tests_csv = pd.read_csv(\"DATA\\\\labels_tests.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "mighty-immune",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Melange la liste\n",
    "labels = list(labels_csv.values)\n",
    "random.shuffle(labels) #Il faut absolument shuffle pour train\n",
    "\n",
    "labels_tests = list(labels_tests_csv.values) #Il ne faut pas shuffle pour test\n",
    "\n",
    "#Créé un dictionnaire qui associe le nom du label et un numérique afin de le mettre dans le modele\n",
    "labels_n = {}\n",
    "for i,label in enumerate(labels_name.values):\n",
    "    labels_n[label[0]] = i\n",
    "    labels_n[i] = label[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prepared-adventure",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "rocky-multimedia",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "amazing-fluid",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parametres du generator\n",
    "batch_size = 50\n",
    "fps = 5 #Pour une shape de 12 (à définir avant de faire le modele)\n",
    "size = (160,120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "capital-destiny",
   "metadata": {},
   "outputs": [],
   "source": [
    "#homemade_fit_generator(model_stolen_saved, labels, batch_size = batch_size, epochs = 3, fps = fps, size = size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "urban-failure",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "irish-prescription",
   "metadata": {},
   "source": [
    "## Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "separated-grounds",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape de y_num = (16,) n° DATA\\V_tests\\video_500.avi       \n",
      "shape de y après categorisation = (16, 13)\n"
     ]
    }
   ],
   "source": [
    "X_test, y_test, _ = my_gen(labels_tests, \"DATA\\\\V_tests\",batch_size = 1000,fps = fps, size = size)\n",
    "#Grand batch_size afin de prendre toutes les données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "pleasant-treasury",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model_stolen_saved.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "average-yield",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "robust-savannah",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 13)\n",
      "(16,)\n",
      "(16, 13)\n"
     ]
    }
   ],
   "source": [
    "print(y_pred.shape)\n",
    "print(y_pred_arg.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "banner-times",
   "metadata": {},
   "source": [
    "### visu résultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "lasting-customer",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fidle.pwk as pwk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "casual-hartford",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of multilabel-indicator and multiclass targets",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-3bc3bbfb413d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0my_pred_arg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mpwk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot_confusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_pred_arg\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnb_classes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Documents\\Scolaire\\M1\\Systèmes_Intelligents\\Hand_Gesture_Recognition\\fidle\\pwk.py\u001b[0m in \u001b[0;36mplot_confusion_matrix\u001b[1;34m(y_true, y_pred, target_names, title, cmap, normalize, figsize, digit_format, save_as)\u001b[0m\n\u001b[0;32m    499\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    500\u001b[0m     \"\"\"\n\u001b[1;32m--> 501\u001b[1;33m     \u001b[0mcm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtarget_names\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    502\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    503\u001b[0m     \u001b[0maccuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcm\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\DL\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\DL\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36mconfusion_matrix\u001b[1;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[0;32m    294\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m     \"\"\"\n\u001b[1;32m--> 296\u001b[1;33m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    297\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"binary\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"multiclass\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%s is not supported\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\DL\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m         raise ValueError(\"Classification metrics can't handle a mix of {0} \"\n\u001b[0m\u001b[0;32m     93\u001b[0m                          \"and {1} targets\".format(type_true, type_pred))\n\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Classification metrics can't handle a mix of multilabel-indicator and multiclass targets"
     ]
    }
   ],
   "source": [
    "y_pred_arg = np.argmax(y_pred, axis=-1)\n",
    "pwk.plot_confusion_matrix(y_test,y_pred_arg,range(nb_classes),normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "anticipated-vision",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brave-museum",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sufficient-pickup",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "insured-contact",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "resident-essex",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worse-champion",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moved-allah",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "musical-olympus",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occupational-relay",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "genuine-fourth",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "modern-monday",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abstract-responsibility",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loose-plumbing",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pregnant-acrobat",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
